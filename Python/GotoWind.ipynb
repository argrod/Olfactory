{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from mpmath import besseli\n",
    "import utm\n",
    "import pyproj, datetime\n",
    "from statistics import mode\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goto wind estimation\n",
    "\n",
    "Originating in the [2016 paper](https://www.science.org/doi/10.1126/sciadv.1700097), this method was originally written for R. Here, we will translate it to work in Python, and try to improve run speeds as well. Comparisons will be made across methods to ensure differences are not being produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplingInterval = 60\n",
    "timeWindow = 51\n",
    "cutlength = 45\n",
    "cutv = 4.1667\n",
    "constv = 34.7/3.6\n",
    "\n",
    "def Likelihoodww(data1,data2,cv): # calculate log-likelihood of the model\n",
    "    def f(par):\n",
    "        a = par[1]\n",
    "        b = cv/sp.gamma(1+1/a)\n",
    "        mx = par[2]\n",
    "        my = par[3]\n",
    "        wx = par[4]\n",
    "        wy = par[5]\n",
    "        L = 0\n",
    "        for i in range(len(data1)):\n",
    "            rr = np.sqrt((data1[i]*np.cos(data2[i]) - wx)**2 + (data1[i]*np.sin(data2[i]) - wy)**2)\n",
    "            rx = (data1[i]*np.cos(data2[i])-wx)/rr\n",
    "            ry = (data1[i]*np.sin(data2[i])-wy)/rr\n",
    "            lp = (a-2)*math.log(rr) - (rr/b)**a + mx*rx + my*ry + math.log(a) - math.log(b) + (1-a)*math.log(b) - math.log(besseli(np.sqrt(mx**2 + my**2),0,))\n",
    "            L = L+lp\n",
    "        return L\n",
    "\n",
    "def Weibull_sd(a,b): # standard deviation of Weibull distribution\n",
    "    return b*np.sqrt(sp.gamma(1+2/a) - sp.gamma(1+1/a)*sp.gamma(1+1/a))\n",
    "\n",
    "def Weibull_mean(a,b): # mean of Weibull distribution\n",
    "    return b*sp.gamma(1+1/a)\n",
    "\n",
    "def Von_Mises_sd(kappa): # standard deviation of von Mises distribution\n",
    "    return 1/np.sqrt(kappa)\n",
    "\n",
    "def readAxyGPS(filename): # read in AxyTrek GPS data (txt files)\n",
    "    df = pd.read_csv(filename, sep = \"\\t\", header = None, usecols = [0,1,2,3],\n",
    "    names = ['Date','Time','lat','lon'])\n",
    "    df['DT'] = pd.to_datetime(df['Date'] + \" \" + df['Time'],format=\"%d/%m/%Y %H:%M:%S\")\n",
    "    return df\n",
    "\n",
    "def nearest(items, pivot): # find the nearest time position\n",
    "    return min(items, key=lambda x: abs(x - pivot))\n",
    "\n",
    "def timeRescale(dat,tdiff): # calculated indeces for rescaling time (DT) for regular sampling every tdiff mins\n",
    "    return dat.iloc[np.arange(0,len(dat),step=np.timedelta64(tdiff,'m')/np.timedelta64(mode(np.diff(dat['DT'])),'s')).astype(int),:]\n",
    "\n",
    "def spTrav(DT,lat,lon,threshold=0): # speed from time (DT), lat, and lon\n",
    "    geod = pyproj.Geod(ellps='WGS84')\n",
    "    _, _, distance = geod.inv(lon[0:-2],lat[0:-2],lon[1:-1],lat[1:-1])\n",
    "    speed = (distance*10**-3)/np.array(np.diff(DT)/np.timedelta64(3600,'s'))\n",
    "    if threshold != 0:\n",
    "        while np.nanmax(speed) > threshold:\n",
    "            lat = lat[speed < threshold]\n",
    "            lon = lon[speed < threshold]\n",
    "            _, _, distance = geod.inv(lon[0:-2],lat[0:-2],lon[1:-1],lat[1:-1])\n",
    "            speed = (distance*10**-3)/np.array(np.diff(DT)/np.timedelta64(3600,'s'))\n",
    "    return distance, speed\n",
    "\n",
    "def XYfromUTM(lat,lon):\n",
    "    return utm.from_latlon(lat,lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "import os, re, glob, pyproj, math, datetime\n",
    "if platform == \"darwin\":\n",
    "    fileloc = \"/Volumes/GoogleDrive-112399531131798335686/My Drive/PhD/Data/2018Shearwater/AxyTrek/\"\n",
    "else:\n",
    "    fileloc = \"I:/My Drive/PD/Data/2018Shearwater/AxyTrek/\"\n",
    "# list all files\n",
    "files = glob.glob(fileloc + \"**/*.txt\")\n",
    "tags = np.unique([re.search('(AxyTrek[\\\\\\\\|/][0-9\\-]+)[\\\\\\\\|/]',f).group(1) for f in files])\n",
    "dat = readAxyGPS(files[1]) # read in\n",
    "minDat = timeRescale(dat,1) # convert to 1 min fs\n",
    "dt = (np.diff(minDat['DT']) / np.timedelta64(1,'s')).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation system\n",
    "\n",
    "Once the data are read in, the initial portion of the program deals with idnetifying suitable windows to run the estimation model. These windows are required to by 51 minutes (approximately) in length, and within those 51 minutes, have over 45 samples, assuming a sampling frequency of 1 fix per minute. We assume there to be some error in the sampling interval. In the original study, this was taken as 5 seconds (i.e. we can expect samples to be 60 $\\pm$ 5 seconds).\n",
    "\n",
    "Starting from the first possible startpoint (half the window size in samples), the model then runs through the following processes:\n",
    "\n",
    "1. Define window size.\n",
    "   1. Find position of data which is 25.5 minutes after initial point.\n",
    "   2. Repeat but for before initial point.\n",
    "   3. Assign these positions as start and end of the window.\n",
    "2. Create a new vector of track speed and direction where the speed is above the threshold of 4.1667 m/s, the sample is within 65 s of the previous sample, and direction is not equal to 100.\n",
    "\n",
    "At this stage, the model starts to run through a variety of 'initial headings', set as each integer between -3 and 3. For each initial heading, the following processes are run:\n",
    "\n",
    "1. Create variable `inita` as a random variable generated from a normal distribution with mean 12.5 and standard deviation 5. `inita` must be greater than 5.\n",
    "2. Calculate the mean heading from all headings within the window that passed the above requirements.\n",
    "3. The sum of the initial heading and the mean heading is determined, and using these data, the following variables are estimated:\n",
    "   1. `kappa`: the concentration parameter for a von Mises distribution\n",
    "   2. `mux` and `muy`: the x and y components of `kappa`\n",
    "   3. `wx` and `wy`: the x and y components of wind (the track vector - the heading)\n",
    "4. The `inita`, `mux`, `muy`, `wx`, and `wy` variables are then optimised using log-likelihood and track speed and direction data alongside a constant assumed mean air speed (34.7 m/s).\n",
    "5. The standard deviation of the heading vector perpendicular to the mean direction `yoko` and the standard deviation of the heading vector along the mean direction `tate` are calculated.\n",
    "\n",
    "If convergence is not reached but `tate` can be calculated, the process is repeated until convergence is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y,_,_ = XYfromUTM(np.array(minDat['lat']),np.array(minDat['lon']))\n",
    "vg_x_obs = np.diff(X)\n",
    "vg_y_obs = np.diff(Y)\n",
    "track_speed = np.sqrt(vg_y_obs**2 + vg_x_obs**2)/dt\n",
    "track_direction = [math.atan2(vg_y_obs[x],vg_x_obs[x]) for x in range(len(vg_x_obs))]\n",
    "time_window = 51\n",
    "cutlength = 45\n",
    "cutv = 4.1667\n",
    "constv = 34.7/3.6\n",
    "sampling_interval = np.timedelta64(mode(np.diff(dat['DT'])),'s').astype(int)\n",
    "error_of_sampling_interval = 5\n",
    "cutt = sampling_interval + error_of_sampling_interval\n",
    "winwidth = time_window - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrow = track_speed\n",
    "drow = track_direction\n",
    "tp = dat['DT']\n",
    "startpoint = math.floor((winwidth*(60/sampling_interval))/2)\n",
    "endpoint = len(rrow) - startpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenize import Double\n",
    "\n",
    "\n",
    "def findWindow(dt,center,windwidthsec):\n",
    "    entr = 0\n",
    "    passesE = False\n",
    "    for qf in range(len(dt) - center):\n",
    "        entr = entr + dt[center + qf]\n",
    "        if entr > windwidthsec:\n",
    "            passesE = True\n",
    "            break\n",
    "    entr = 0\n",
    "    passesS = False\n",
    "    for qb in range(center-1):\n",
    "        entr = entr + dt[center-qb]\n",
    "        if entr > windwidthsec:\n",
    "            passesS = True\n",
    "            break\n",
    "    return passesE * passesS * (passesE - passesS > 44)\n",
    "\n",
    "def trackVectors(id_hd,r,d,index):\n",
    "    rr = []\n",
    "    dd = []\n",
    "    iindex = []\n",
    "    for k in range(len(r)):\n",
    "        if r[k] > cutv:\n",
    "            rr = np.append(rr,r)\n",
    "            dd = np.append(dd,d)\n",
    "            iindex = np.append(iindex,index[k])\n",
    "    inithd_first = id_hd/(3*pi/2)\n",
    "    inita = 0\n",
    "    while inita < 5:\n",
    "        inita = np.abs(np.random.normal(12.5,5))\n",
    "    meangd = np.arctan2(np.sum(np.sin(d)),np.sum(np.cos(d)))\n",
    "    inithd = meangd + inithd_first\n",
    "    initkappa = \n",
    "\n",
    "    np.mean(np.cos(d - meangd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findWindow(dt,center,(51/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0634833707413236"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.special.iv(0,.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a1(r):\n",
    "    return sp.special.iv(1,r) / sp.special.iv(0,r)\n",
    "# def a1inv(r):\n",
    "#     return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19610381221799555"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.special.iv(1,.4) / sp.special.iv(0,.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In R, the function `A1inv` returns a value `k` from input argument `r` such that\n",
    "\n",
    "$A1inv(k) = A1(r)$\n",
    "\n",
    "where \n",
    "\n",
    "$A1(r) = \\frac{I_1(\\kappa)}{I_0(\\kappa)}$\n",
    "\n",
    "where $I_1$ and $I_0$ are the first and zeroth order Bessel functions, respectively.\n",
    "\n",
    "However, Python does not have such a function, and so this estimate for `k` must be calculated through maximum likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14833742694087523"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1(.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/aran/Documents/GitHub/Olfactory/Python/GotoWind.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aran/Documents/GitHub/Olfactory/Python/GotoWind.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sp\u001b[39m.\u001b[39;49moptimize\u001b[39m.\u001b[39;49mminimize(a1inv,\u001b[39m.4\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/scipy/optimize/_minimize.py:694\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    692\u001b[0m     res \u001b[39m=\u001b[39m _minimize_cg(fun, x0, args, jac, callback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    693\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbfgs\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 694\u001b[0m     res \u001b[39m=\u001b[39m _minimize_bfgs(fun, x0, args, jac, callback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    695\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    696\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    697\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/scipy/optimize/_optimize.py:1283\u001b[0m, in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[39mif\u001b[39;00m maxiter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     maxiter \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(x0) \u001b[39m*\u001b[39m \u001b[39m200\u001b[39m\n\u001b[0;32m-> 1283\u001b[0m sf \u001b[39m=\u001b[39m _prepare_scalar_function(fun, x0, jac, args\u001b[39m=\u001b[39;49margs, epsilon\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m   1284\u001b[0m                               finite_diff_rel_step\u001b[39m=\u001b[39;49mfinite_diff_rel_step)\n\u001b[1;32m   1286\u001b[0m f \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39mfun\n\u001b[1;32m   1287\u001b[0m myfprime \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39mgrad\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/scipy/optimize/_optimize.py:263\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    259\u001b[0m     bounds \u001b[39m=\u001b[39m (\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf, np\u001b[39m.\u001b[39minf)\n\u001b[1;32m    261\u001b[0m \u001b[39m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m sf \u001b[39m=\u001b[39m ScalarFunction(fun, x0, args, grad, hess,\n\u001b[1;32m    264\u001b[0m                     finite_diff_rel_step, bounds, epsilon\u001b[39m=\u001b[39;49mepsilon)\n\u001b[1;32m    266\u001b[0m \u001b[39mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:158\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx)\n\u001b[1;32m    157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun_impl \u001b[39m=\u001b[39m update_fun\n\u001b[0;32m--> 158\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[1;32m    160\u001b[0m \u001b[39m# Gradient evaluation\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mif\u001b[39;00m callable(grad):\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:148\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    143\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    144\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe user-provided objective function \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmust return a scalar value.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m \u001b[39mif\u001b[39;00m fx \u001b[39m<\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lowest_f:\n\u001b[1;32m    149\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lowest_x \u001b[39m=\u001b[39m x\n\u001b[1;32m    150\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lowest_f \u001b[39m=\u001b[39m fx\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "sp.optimize.minimize(a1inv,.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
